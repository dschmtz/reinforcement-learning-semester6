{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import environment.trading_environment as env\n",
    "from agent.dqn import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio balance: 100000\n",
      "Stocks in portfolio: 0\n"
     ]
    }
   ],
   "source": [
    "portfolio = env.setup_environment()\n",
    "print(\"Portfolio balance:\", portfolio.balance)\n",
    "print(\"Stocks in portfolio:\", len(portfolio.stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periode: 5941, Total Reward: -0.22121892869472504, 0.0029985904693603516\n",
      "Periode: 5961, Total Reward: -0.9703559726476669, 0.007000923156738281\n",
      "Periode: 5981, Total Reward: -1.5826144218444824, 0.012000083923339844\n",
      "Periode: 6001, Total Reward: -1.7424651384353638, 80.27382206916809\n",
      "Periode: 6021, Total Reward: -2.894345313310623, 240.0141463279724\n",
      "Periode: 6041, Total Reward: -4.413776531815529, 403.83090591430664\n",
      "Periode: 6061, Total Reward: -4.475036859512329, 568.679196357727\n",
      "Periode: 6081, Total Reward: -5.76616433262825, 731.7647500038147\n",
      "Periode: 6101, Total Reward: -5.733551666140556, 891.1326291561127\n",
      "Periode: 6121, Total Reward: -5.0299995839595795, 1053.8594057559967\n",
      "Periode: 6141, Total Reward: -5.345068246126175, 1215.5389816761017\n",
      "Periode: 6161, Total Reward: -4.678825616836548, 1377.9056468009949\n",
      "Episode: 1, Total Reward: -4.009752452373505\n"
     ]
    }
   ],
   "source": [
    "agent = DQN(action_space=3) # 3 possible actions\n",
    "\n",
    "actions = {\n",
    "    0: \"Hold\",\n",
    "    1: \"Buy\",\n",
    "    2: \"Sell\"\n",
    "}\n",
    "\n",
    "def step(actions):\n",
    "    \"\"\"\n",
    "    Transition method\n",
    "    \"\"\"\n",
    "    action = np.argmax(actions)\n",
    "    value_before = portfolio.get_value()\n",
    "\n",
    "    if action == 0:\n",
    "        # Hold\n",
    "        pass\n",
    "    if action == 1:\n",
    "        # Buy\n",
    "        try:\n",
    "            portfolio.buy(\"AAPL\", 1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if action == 2:\n",
    "        # Sell\n",
    "        try:\n",
    "            portfolio.sell(\"AAPL\", 1)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    portfolio.market.update_prices()\n",
    "\n",
    "    state = portfolio.get_state()\n",
    "    reward = portfolio.get_value() - value_before\n",
    "    return state, reward\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 1\n",
    "for episode in range(num_episodes):\n",
    "    # Reset environment\n",
    "    portfolio.reset()\n",
    "    portfolio.market.time_offset = 90\n",
    "\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    # 0-6046 Training/Val - 90\n",
    "    num_training_period = 6046\n",
    "    num_training_period = 6177\n",
    "    for period in range(5927, num_training_period):\n",
    "        if(period % 20 == 0):\n",
    "            print(f\"Periode: {period}, Total Reward: {total_reward}, {time.time()-start_time}\")\n",
    "        state = portfolio.get_state()\n",
    "\n",
    "        # \n",
    "        action = agent.act(state)\n",
    "        next_state, reward = step(action)\n",
    "\n",
    "        if period == (num_training_period - 1):\n",
    "            done = True\n",
    "\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        total_reward += reward\n",
    "\n",
    "        \n",
    "        agent.replay()\n",
    "        \"\"\"\n",
    "        try:\n",
    "            agent.replay()\n",
    "        except:\n",
    "            print(next_state)\n",
    "            break\"\"\"\n",
    "\n",
    "    print(f\"Episode: {episode+1}, Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save_weights(\"models/aapl/dqn_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49983.60980850458"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': 40}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apple 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periode: 6441, Total Reward: -733.6652374267578, 0.0010235309600830078\n",
      "Periode: 6461, Total Reward: -1467.6183319091797, 0.004232645034790039\n",
      "Periode: 6481, Total Reward: -1711.104507446289, 0.007359504699707031\n",
      "Periode: 6501, Total Reward: -2066.84871673584, 63.620696783065796\n",
      "Periode: 6521, Total Reward: -5560.7037353515625, 222.1989140510559\n",
      "Periode: 6541, Total Reward: -5053.833427429199, 381.1625506877899\n",
      "Periode: 6561, Total Reward: -4820.616874694824, 540.8446314334869\n",
      "Periode: 6581, Total Reward: -5376.410140991211, 700.1521980762482\n",
      "Periode: 6601, Total Reward: -6053.29891204834, 859.9111132621765\n",
      "Periode: 6621, Total Reward: -5177.950401306152, 1015.0899639129639\n",
      "Periode: 6641, Total Reward: -2624.9535369873047, 1168.1283831596375\n",
      "Periode: 6661, Total Reward: -1582.3918151855469, 1321.6982922554016\n",
      "Episode: 1, Total Reward: 4987.09342956543\n",
      "108\n",
      "0\n",
      "42227.31643676758\n",
      "{'AAPL': 830}\n",
      "****************************************\n",
      "Periode: 6441, Total Reward: 50.116310119628906, 1560.2655401229858\n",
      "Periode: 6461, Total Reward: 683.3123016357422, 1714.2011206150055\n",
      "Periode: 6481, Total Reward: 1671.6775131225586, 1867.9513823986053\n",
      "Periode: 6501, Total Reward: 3614.6117401123047, 2022.123316526413\n",
      "Periode: 6521, Total Reward: -125.71693420410156, 2177.0178232192993\n",
      "Periode: 6541, Total Reward: 3256.267318725586, 2331.5620794296265\n",
      "Periode: 6561, Total Reward: 3460.1819229125977, 2486.6488933563232\n",
      "Periode: 6581, Total Reward: 4749.631462097168, 2641.710932970047\n",
      "Periode: 6601, Total Reward: 9120.785522460938, 2797.7799882888794\n",
      "Periode: 6621, Total Reward: 15212.558326721191, 2953.3498711586\n",
      "Periode: 6641, Total Reward: 25886.622924804688, 3109.0448713302612\n",
      "Periode: 6661, Total Reward: 28760.255012512207, 3265.064359664917\n",
      "Episode: 2, Total Reward: 46944.31735992432\n",
      "307\n",
      "0\n",
      "252.79041290283203\n",
      "{'AAPL': 1940}\n",
      "****************************************\n",
      "Periode: 6441, Total Reward: 59.764137268066406, 3507.4394977092743\n",
      "Periode: 6461, Total Reward: 791.38916015625, 3664.2837450504303\n",
      "Periode: 6481, Total Reward: 1815.3452682495117, 3821.086730480194\n",
      "Periode: 6501, Total Reward: 4387.568206787109, 3980.8029940128326\n",
      "Periode: 6521, Total Reward: 142.9901885986328, 4138.276814460754\n",
      "Periode: 6541, Total Reward: 3541.445083618164, 4296.02333855629\n",
      "Periode: 6561, Total Reward: 4337.559127807617, 4453.314564704895\n",
      "Periode: 6581, Total Reward: 5786.427001953125, 4611.388503074646\n",
      "Periode: 6601, Total Reward: 10673.485832214355, 4771.177576303482\n",
      "Periode: 6621, Total Reward: 17408.914642333984, 4932.207562923431\n",
      "Periode: 6641, Total Reward: 29791.650886535645, 5095.605845212936\n",
      "Periode: 6661, Total Reward: 32850.516929626465, 5260.444524049759\n",
      "Episode: 3, Total Reward: 53149.81243133545\n",
      "510\n",
      "0\n",
      "409.15035247802734\n",
      "{'AAPL': 2020}\n",
      "****************************************\n",
      "510\n",
      "0\n",
      "409.15035247802734\n",
      "{'AAPL': 2020}\n"
     ]
    }
   ],
   "source": [
    "agent = DQN(action_space=3)\n",
    "\n",
    "actions = {\n",
    "    0: \"Hold\",\n",
    "    1: \"Buy\",\n",
    "    2: \"Sell\"\n",
    "}\n",
    "\n",
    "num_buys = 0\n",
    "num_sells = 0\n",
    "\n",
    "def step(actions):\n",
    "    \"\"\"\n",
    "    Transition method\n",
    "    \"\"\"\n",
    "    action = np.argmax(actions)\n",
    "    value_before = portfolio.get_value()\n",
    "\n",
    "    global num_buys, num_sells\n",
    "\n",
    "    if action == 0:\n",
    "        # Hold\n",
    "        pass\n",
    "    if action == 1:\n",
    "        # Buy\n",
    "        try:\n",
    "            portfolio.buy(\"AAPL\", 10)\n",
    "            num_buys += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if action == 2:\n",
    "        # Sell\n",
    "        try:\n",
    "            portfolio.sell(\"AAPL\", 10)\n",
    "            num_sells += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    portfolio.market.update_prices()\n",
    "\n",
    "    state = portfolio.get_state()\n",
    "    reward = portfolio.get_value() - value_before\n",
    "    return state, reward\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 3\n",
    "for episode in range(num_episodes):\n",
    "    # Reset environment\n",
    "    portfolio.reset()\n",
    "    portfolio.market.time_offset = 6429\n",
    "\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    # 0-6046 Training/Val - 90\n",
    "    num_training_period = 6046\n",
    "    num_training_period = 6680\n",
    "    for period in range(6429, num_training_period):\n",
    "        if(period % 20 == 0):\n",
    "            print(f\"Periode: {period}, Total Reward: {total_reward}, {time.time()-start_time}\")\n",
    "        state = portfolio.get_state()\n",
    "\n",
    "        # \n",
    "        action = agent.act(state)\n",
    "        next_state, reward = step(action)\n",
    "\n",
    "        if period == (num_training_period - 1):\n",
    "            done = True\n",
    "\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        total_reward += reward\n",
    "\n",
    "        \n",
    "        agent.replay()\n",
    "\n",
    "    print(f\"Episode: {episode+1}, Total Reward: {total_reward}\")\n",
    "    print(num_buys)\n",
    "    print(num_sells)\n",
    "    print(portfolio.balance)\n",
    "    print(portfolio.stocks)\n",
    "    print(\"*\" * 40)\n",
    "\n",
    "# 6047-7555 Test\n",
    "print(num_buys)\n",
    "print(num_sells)\n",
    "print(portfolio.balance)\n",
    "print(portfolio.stocks)\n",
    "\n",
    "agent.model.save_weights(\"models/aapl/dqn_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procter & Gamble 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periode: 6441, Total Reward: 20.55511474609375, 0.00099945068359375\n",
      "Periode: 6461, Total Reward: -3360.005111694336, 0.004015922546386719\n",
      "Periode: 6481, Total Reward: -6907.150115966797, 0.0060155391693115234\n",
      "Periode: 6501, Total Reward: -10623.841018676758, 64.60846042633057\n",
      "Periode: 6521, Total Reward: -10512.779922485352, 222.98028349876404\n",
      "Periode: 6541, Total Reward: -14078.035507202148, 381.69393014907837\n",
      "Periode: 6561, Total Reward: -15612.514114379883, 540.1401376724243\n",
      "Periode: 6581, Total Reward: -16755.307693481445, 698.7172634601593\n",
      "Periode: 6601, Total Reward: -17808.06182861328, 857.5554149150848\n",
      "Periode: 6621, Total Reward: -18988.347091674805, 1011.5089685916901\n",
      "Periode: 6641, Total Reward: -19174.928894042954, 1162.832004070282\n",
      "Periode: 6661, Total Reward: -20560.03387451172, 1314.194213628769\n",
      "Episode: 1, Total Reward: -20828.045349121094\n",
      "96\n",
      "0\n",
      "139.61441040039062\n",
      "{'PG': 700}\n",
      "****************************************\n",
      "Periode: 6441, Total Reward: 134.43603515625, 1549.5809381008148\n",
      "Periode: 6461, Total Reward: 2.708587646484375, 1709.1132011413574\n",
      "Periode: 6481, Total Reward: 127.28347778320312, 1869.3948721885681\n",
      "Periode: 6501, Total Reward: 556.1970520019531, 2032.268733739853\n",
      "Periode: 6521, Total Reward: 2204.376449584961, 2193.74307179451\n",
      "Periode: 6541, Total Reward: 4014.901657104492, 2354.2760231494904\n",
      "Periode: 6561, Total Reward: 6406.675567626953, 2513.9850113391876\n",
      "Periode: 6581, Total Reward: 10256.884765625, 2667.283945083618\n",
      "Periode: 6601, Total Reward: 10783.53042602539, 2821.0724997520447\n",
      "Periode: 6621, Total Reward: 11060.732421875, 2976.055507659912\n",
      "Periode: 6641, Total Reward: 11099.76684570314, 3130.5167236328125\n",
      "Periode: 6661, Total Reward: 15693.206481933594, 3286.254175424576\n",
      "Episode: 2, Total Reward: 14173.642044067383\n",
      "203\n",
      "0\n",
      "141.26541137695312\n",
      "{'PG': 1010}\n",
      "****************************************\n",
      "Periode: 6441, Total Reward: 175.1628875732422, 3527.891241312027\n",
      "Periode: 6461, Total Reward: -684.0272521972656, 3683.2077012062073\n",
      "Periode: 6481, Total Reward: 567.3105621337891, 3849.5902950763702\n",
      "Periode: 6501, Total Reward: 1105.4485321044922, 4014.5243740081787\n",
      "Periode: 6521, Total Reward: 3034.069290161133, 4181.826020717621\n",
      "Periode: 6541, Total Reward: 7469.441223144531, 4345.54972743988\n",
      "Periode: 6561, Total Reward: 11299.290161132812, 4509.1673312187195\n",
      "Periode: 6581, Total Reward: 15303.21792602539, 4671.592721700668\n",
      "Periode: 6601, Total Reward: 15850.516357421875, 4834.782766580582\n",
      "Periode: 6621, Total Reward: 16138.58901977539, 4998.951729297638\n",
      "Periode: 6641, Total Reward: 16179.15420532228, 5167.894344329834\n",
      "Periode: 6661, Total Reward: 20952.728729248047, 5338.000014305115\n",
      "Episode: 3, Total Reward: 20546.882781982422\n",
      "311\n",
      "0\n",
      "869.3389892578125\n",
      "{'PG': 1060}\n",
      "****************************************\n",
      "311\n",
      "0\n",
      "869.3389892578125\n",
      "{'PG': 1060}\n"
     ]
    }
   ],
   "source": [
    "agent = DQN(action_space=3)\n",
    "\n",
    "actions = {\n",
    "    0: \"Hold\",\n",
    "    1: \"Buy\",\n",
    "    2: \"Sell\"\n",
    "}\n",
    "\n",
    "num_buys = 0\n",
    "num_sells = 0\n",
    "\n",
    "def step(actions):\n",
    "    \"\"\"\n",
    "    Transition method\n",
    "    \"\"\"\n",
    "    action = np.argmax(actions)\n",
    "    value_before = portfolio.get_value()\n",
    "\n",
    "    global num_buys, num_sells\n",
    "\n",
    "    if action == 0:\n",
    "        # Hold\n",
    "        pass\n",
    "    if action == 1:\n",
    "        # Buy\n",
    "        try:\n",
    "            portfolio.buy(\"PG\", 10)\n",
    "            num_buys += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if action == 2:\n",
    "        # Sell\n",
    "        try:\n",
    "            portfolio.sell(\"PG\", 10)\n",
    "            num_sells += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    portfolio.market.update_prices()\n",
    "\n",
    "    state = portfolio.get_state()\n",
    "    reward = portfolio.get_value() - value_before\n",
    "    return state, reward\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 3\n",
    "for episode in range(num_episodes):\n",
    "    # Reset environment\n",
    "    portfolio.reset()\n",
    "    portfolio.market.time_offset = 6429\n",
    "\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    # 0-6046 Training/Val - 90\n",
    "    num_training_period = 6046\n",
    "    num_training_period = 6680\n",
    "    for period in range(6429, num_training_period):\n",
    "        if(period % 20 == 0):\n",
    "            print(f\"Periode: {period}, Total Reward: {total_reward}, {time.time()-start_time}\")\n",
    "        state = portfolio.get_state()\n",
    "\n",
    "        # \n",
    "        action = agent.act(state)\n",
    "        next_state, reward = step(action)\n",
    "\n",
    "        if period == (num_training_period - 1):\n",
    "            done = True\n",
    "\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        total_reward += reward\n",
    "\n",
    "        \n",
    "        agent.replay()\n",
    "\n",
    "    print(f\"Episode: {episode+1}, Total Reward: {total_reward}\")\n",
    "    print(num_buys)\n",
    "    print(num_sells)\n",
    "    print(portfolio.balance)\n",
    "    print(portfolio.stocks)\n",
    "    print(\"*\" * 40)\n",
    "\n",
    "# 6047-7555 Test\n",
    "print(num_buys)\n",
    "print(num_sells)\n",
    "print(portfolio.balance)\n",
    "print(portfolio.stocks)\n",
    "\n",
    "agent.model.save_weights(\"models/pg/dqn_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
